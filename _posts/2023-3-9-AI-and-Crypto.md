---
layout: post
author: OAX Foundation
image: /img/blog-images/OAX-AI-Header.png
tag: industry-business
---

![]({{ site.baseurl }}/img/blog-images/OAX-AI-Header.png)

<br><b>AI and Crypto</b>

A.I. has been having its moment in the limelight recently since the launch of ChatGPT. Having launched November 2022, the platform recorded a million users within the first week and took over the trends over the holiday season. Of course we saw Google immediately gearing up trying to rise to the challenge with their response “Bard”. And yet the launch of Bard was disappointing for so many waiting to see a fierce A.I. battle.

The development of A.I. begun long ago, and even the chatbots that we interact with often for customer service are first the first layer. But ChatGPT has suddenly brought a whole new world of possibility to the general market and has been exciting people in recent months. But what does this mean for the world of digital assets? We break up a few key trends and the implications it might have on this space below.

<br>
<b>A.I. Tokens</b>
When it comes to A.I. tokens, in the larger span of things it realistically has the shortest term impact. A.I. related tokens have been getting a fair bit of attention over the last few months simply for the additional attention that ChatGPThas brought to the industry, and as a result seeing gains in the market. However, there may be even less direct impact with A.I. tokens in respect to the changes in the industry as compared to the Metaverse related tokens that were the center of attention last year. While some of these A.I. tokens may be connected to very promising projects, we caution community members to evaluate the projects for their potential and not just as a result of the hype. Of course while some of these tokens may be legitimate, we urge our community to exercise caution, for there are also many that will be scams. Peckshield recently flagged multiple pump-and-dump schemes– so remember to be careful when looking into any future projects!

But the far more interesting A.I. integration goes far beyond just tokens and may lead to much more substantial changes to the industry.

<br>
<b>Using A.I. for Development</b>
Time and time again, we’ve talked about the time required to develop things that are ready for the market and even then, not everything sees the light of day. But development work still needs to be done to know whether it can work and bring value. Reviewing code versus starting from scratch can make a big difference in the development timeline, and the prospective use of A.I. like ChatGPT to help with coding may help teams move their timelines and bring products to market faster and with less errors. This might go for the coding in an app, reviewing existing code, or even smart contracts that are the basis of DeFi. 

The boost in support may help expedite the growth in the space and bring more options to the space as we test out what works and doesn’t work. But it comes with a double edge sword, the platform that codes to build it up can quite easily then help to develop code that takes it down. 

<br>
<b>Using A.I. to Build your Brand</b>
The double edged sword that exists when we consider A.I in the development of the digital asset space couldn’t be more obvious when you consider how A.I. can be used in marketing and developing the brand for the crypto market. 

We’ve spoken at length here at OAX regarding the necessity of doing <a href="https://www.oax.org/2022/09/14/Doing-Your-Research-in-a-Crypto-World.html">research and background checks for projects</a>, and protecting yourself from scams. It’s difficult to see through the better developed scams; but oftentimes it might be the little things that give it away. When researching official channels, whether websites or social media, you look for a certain level of professionalism and responsiveness but what happens when everything is handled by a bot? Even for those of a more suspicious nature, this will likely prove challenging when trying to distinguish the real and the fake.

Of course we’re also expecting A.I. to play a huge role in the development and rollout of the metaverse space. As the metaverse experience continues to improve and integrate in a more life-like scenario, it’s likely that most companies will begin upgrading their customer service services. From the bots that currently go around in circles as you struggle to find a “real” representative, the advancement of A.I. will also bring a more helpful and lifelike response. 

Depending on the autonomy that’s given in the coding to adapt answers and the database of learning, A.I. bots will change and evolve. While employees can be held accountable for their actions while representing the company and the potential negative impact begs the question, who would be liable if it was A.I. that harmed a company’s reputation?

![]({{ site.baseurl }}/img/blog-images/OAX-AI-Bing.PNG)
<br><i>Source: <a href="https://www.theverge.com/2023/2/15/23599072/microsoft-ai-bing-personality-conversations-spy-employees-webcams">The Verge</a></i>

Assuming that the details of the conversation are fictional and just to play up to the idea that the user is speaking to someone with a bot with a personality, the question remains, what happens when the “isolated incident” causes corporate reputation harm? 

<br>
<b>Regulated Advice for Trading</b>

“The information and publications are not intended to be and do not constitute financial advice, investment advice, trading advice…”

We’ve all seen the disclaimer on websites and at the end of articles. And despite the T&Cs that may come with an A.I. based platform, if asked “What tokens should I buy” or “What price should I sell”, does the response fall under the space of “trading advice”?

While the information ideally should be pulling up the latest data and information available online, there’s always risks of data lag or just incomplete records. But financial advisors are also expected to weigh the nuances of one's portfolio and expectations before giving advice. What happens when all of that is overlooked and one is given a simplistic “yes or no” answer. 

![]({{ site.baseurl }}/img/blog-images/OAX-AI-Quote.png)

<br>
<b>Good or Bad?</b>

The sudden appearance of ChatGPT, Google’s Bard and other A.I. bots, the hype has come with a side conversation “will A.I. take over our jobs?”. If it can code, and it can create marketing text and prompt trading advice not overseen by regulators; wouldn’t the tech developers, marketing teams, customer service teams and traders be done for? The simple answer– absolutely… if you believe that responsibility and accountability have no place in society. As A.I aggregates data and “learns” from whatever information is fed to the system, it will pick up the good and the bad, and churn it out indiscriminately.

Humans aren’t always good, and the role of decentralization also stemmed from the idea that you shouldn’t have to “trust” any one person; but it does rely on the collective group to hold things to be accountable. A.I. isn’t trusting in one person, but it is back to a single point of failure model. 

But is it all bad? It’s inevitable that A.I will be used for the development of the digital space, and it can benefit the ecosystem in many ways. There’s so many opportunities that technology can offer, but there’s sure to be many more headlines coming our way in the months to come. 
